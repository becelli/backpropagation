{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from numba import njit\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "vl3oTWgKJQwB"
      },
      "outputs": [],
      "source": [
        "# Backpropagation algorithm\n",
        "# default config for the backpropagation algo\n",
        "l_rate = 0.001\n",
        "max_it = 150\n",
        "min_error = 0.1\n",
        "# obs: changing the learning_rate and the initial weight can improve the performance\n",
        "# the current config is the optimal config found for the hyperbolic tangent until this moment\n",
        "\n",
        "# open the csv file and get the data\n",
        "\n",
        "\n",
        "def get_training_data(filename):\n",
        "    with open(filename) as f:\n",
        "        data = pd.read_csv(f)\n",
        "        data = data.values\n",
        "    return data\n",
        "\n",
        "# choose which curve will be used by the neurons of the net\n",
        "\n",
        "# @njit(parallel=True, fastmath=True, cache=True)\n",
        "\n",
        "@njit(cache=True)\n",
        "def fx_tanh(x: np.ndarray) -> np.ndarray:\n",
        "    return np.tanh(x)\n",
        "\n",
        "@njit(cache=True)\n",
        "def d_fx_tanh(x: np.ndarray) -> np.ndarray:\n",
        "    return (1.0/np.cosh(x))**2.0\n",
        "\n",
        "@njit(cache=True)\n",
        "def fx_logistic(x: np.ndarray) -> np.ndarray:\n",
        "    return 1.0/(1+np.exp(-x))\n",
        "\n",
        "@njit(cache=True)\n",
        "def d_fx_logistic(x: np.ndarray) -> np.ndarray:\n",
        "    return np.exp(x)/(1+np.exp(x))**2.0\n",
        "\n",
        "# @njit(cache=True)\n",
        "def choose_curve(is_logistic: bool) -> tuple:\n",
        "    if is_logistic:\n",
        "        return fx_logistic, d_fx_logistic\n",
        "    else:\n",
        "        return fx_tanh, d_fx_tanh\n",
        "\n",
        "# initialize the weights as small random values\n",
        "\n",
        "\n",
        "@njit(cache=True)\n",
        "def initialize_weights(num_classes: int, num_features: int):\n",
        "    # number of inputs (class features)\n",
        "    num_inputs = num_features\n",
        "    # number of output neurons\n",
        "    num_outputs = num_classes\n",
        "    # number of hidden neurons (geometry mean of inputs and outputs)\n",
        "    num_hidden = int(np.sqrt(num_inputs*num_outputs))\n",
        "    # initialize the weights\n",
        "    # add 0.005 in order to prevent 0\n",
        "    weight_hidden = np.random.rand(num_hidden, num_inputs)/100.0 + 0.0005\n",
        "    weight_output = np.random.rand(num_outputs, num_hidden) * 3.0 - 1.5\n",
        "    # initialize the bias, in this case all bias = 0\n",
        "    bias_hidden = np.zeros((num_hidden, num_inputs))\n",
        "    bias_output = np.zeros((num_outputs, num_hidden))\n",
        "    return weight_hidden, weight_output, bias_hidden, bias_output\n",
        "\n",
        "# calculate the output from each neuron of the given layer\n",
        "# each layer is described by set of weights of each neuron\n",
        "\n",
        "\n",
        "def calculate_layer(weights_layer, fx, layer_inputs):\n",
        "    net: np.ndarray = np.dot(layer_inputs, weights_layer.T)\n",
        "    output = fx(net)\n",
        "    return output\n",
        "\n",
        "# calculate the expected output for the class\n",
        "\n",
        "\n",
        "# @njit(cache=True)\n",
        "def calculate_expected_values(is_logistic, class_number, num_classes):\n",
        "    if is_logistic:\n",
        "        expected_values = np.zeros(num_classes)\n",
        "        expected_values[class_number-1] = 1\n",
        "        return expected_values\n",
        "    else:\n",
        "        expected_values = np.full(num_classes, -1)\n",
        "        expected_values[class_number-1] = 1\n",
        "        return expected_values\n",
        "\n",
        "# calculate the error for the output layer\n",
        "\n",
        "@njit(cache=True)\n",
        "def calculate_output_error(is_logistic, weights, expected, attained, inputs, fx, d_fx):\n",
        "    error = (expected - attained)*d_fx(inputs)\n",
        "    return error\n",
        "\n",
        "# calculate the error for the hidden layer\n",
        "# needs revision\n",
        "\n",
        "def calculate_hidden_error(is_logistic, weights_hidden, weights_output, error_output, inputs, fx, d_fx):\n",
        "    error = error_output @ weights_output\n",
        "    hidden = inputs @ weights_hidden.T\n",
        "    return  error*d_fx(hidden)\n",
        "    # return error\n",
        "\n",
        "\n",
        "# adjust the weights of a given layer according to the layer error\n",
        "\n",
        "@njit(cache=True)\n",
        "def adjust_weights(weights, learning_rate, error, layer_input):\n",
        "    new_weights = np.zeros(weights.shape)\n",
        "    for i in range(len(weights)):\n",
        "        new_weights[i] = weights[i] + learning_rate*error[i]*layer_input\n",
        "    return new_weights\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jFC-QSLkbCa0"
      },
      "source": [
        "Treinamento da rede\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "r9ysPZI6bBgt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#training with an unbalanced dataset\n",
        "#train a neuron net with a specificied curve and data\n",
        "def train_through_data(is_logistic, data):\n",
        "  #get information from the dataset\n",
        "  num_classes = np.unique(data[:, -1]).size\n",
        "  num_features = data.shape[1] - 1\n",
        "  sample_size = data.shape[0]\n",
        "\n",
        "  # remove the last column from the inputs list, i.e., remove the class type from inputs\n",
        "  inputs = np.delete(data, len(data[0])-1, 1)\n",
        "  \n",
        "  #initialize the initial weights\n",
        "  weight_hidden, weight_output, bias_hidden, bias_output = initialize_weights(num_classes, num_features)\n",
        "  #get the function for the choosen curve\n",
        "  fx, d_fx = choose_curve(is_logistic)\n",
        "  \n",
        "  \n",
        "  #train until max_it\n",
        "  for j in range(0, max_it):\n",
        "    #train the net for sample in dataset\n",
        "    for i in range(0, sample_size):\n",
        "      #choose a random sample in order to prevent overfitting\n",
        "      new_i = random.randint(0, sample_size-1)\n",
        "      \n",
        "      #calculate the expected value for this set of features\n",
        "      expected_values = calculate_expected_values(is_logistic, data[new_i][-1], num_classes)\n",
        "      \n",
        "      #calculate the value for the hidden layer and the output layer\n",
        "      hidden_values = calculate_layer(weight_hidden, fx, inputs[new_i])\n",
        "      output_values = calculate_layer(weight_output, fx, hidden_values)\n",
        "      \n",
        "      #calculate the error for each layer\n",
        "      error_output_layer = calculate_output_error(is_logistic, weight_output, expected_values, output_values, hidden_values, fx, d_fx)\n",
        "      error_hidden_layer = calculate_hidden_error(is_logistic, weight_hidden, weight_output, error_output_layer, inputs[new_i], fx, d_fx)\n",
        "      \n",
        "      #adjust weights for each layer\n",
        "      weight_output = adjust_weights(weight_output, l_rate, error_output_layer, hidden_values)\n",
        "      weight_hidden = adjust_weights(weight_hidden, l_rate, error_hidden_layer, inputs[new_i])\n",
        "    if(j % 100 == 0):\n",
        "      print(j)\n",
        "  #return the trained values for each layer\n",
        "  return weight_hidden, weight_output\n",
        "\n",
        "\n",
        "\n",
        "# #experimental training with a balanced dataset\n",
        "# def train_through_data(is_logistic, data):\n",
        "#   #get information from the dataset\n",
        "#   num_classes = np.unique(data[:, -1]).size\n",
        "#   num_features = data.shape[1] - 1\n",
        "#   sample_size = len(data)\n",
        "\n",
        "#   #initialize the initial weights\n",
        "#   weight_hidden, weight_output, bias_hidden, bias_output = initialize_weights(num_classes, num_features)\n",
        "#   #get the function for the choosen curve\n",
        "#   fx, d_fx = choose_curve(is_logistic)\n",
        "  \n",
        "#   current_class = 1\n",
        "\n",
        "#   #train until max_it\n",
        "#   for j in range(0, max_it):\n",
        "#     #train the net for sample in dataset\n",
        "#     for i in range(0, sample_size):\n",
        "#       #choose a random sample in order to prevent overfitting\n",
        "#       sample = choose_sample(current_class, data)\n",
        "      \n",
        "#       #separate the class from the inputs list, i.e., remove the class type from inputs\n",
        "#       sample_class = sample[-1]\n",
        "#       inputs = np.delete(sample, len(sample)-1, 0)\n",
        "\n",
        "#       #calculate the expected value for this set of features\n",
        "#       expected_values = calculate_expected_values(is_logistic, sample_class, num_classes)\n",
        "      \n",
        "#       #calculate the value for the hidden layer and the output layer\n",
        "#       hidden_values = calculate_layer(weight_hidden, fx, inputs)\n",
        "#       output_values = calculate_layer(weight_output, fx, hidden_values)\n",
        "      \n",
        "#       #calculate the error for each layer\n",
        "#       error_output_layer = calculate_output_error(is_logistic, weight_output, expected_values, output_values, hidden_values)\n",
        "#       error_hidden_layer = calculate_hidden_error(is_logistic, weight_hidden, weight_output, error_output_layer, inputs)\n",
        "#       #print(\"Expected: \")\n",
        "#       #print(expected_values)\n",
        "#       #print(\"Output: \")\n",
        "#       #print(output_values)\n",
        "      \n",
        "#       #adjust weights for each layer\n",
        "#       weight_output = adjust_weights(weight_output, l_rate, error_output_layer, hidden_values)\n",
        "#       weight_hidden = adjust_weights(weight_hidden, l_rate, error_hidden_layer, inputs)\n",
        "\n",
        "#       current_class %= num_classes\n",
        "#       current_class += 1\n",
        "#     if(j % 100 == 0):\n",
        "#       print(j)\n",
        "#   #return the trained values for each layer\n",
        "#   return weight_hidden, weight_output\n",
        "\n",
        "\"\"\"\"\"\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XE2s_3ZWho05"
      },
      "source": [
        "Testagem da rede\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "K6B6S_yvhoTR"
      },
      "outputs": [],
      "source": [
        "# the assigned class will be the index with the higher value\n",
        "#@njit(cache=True)\n",
        "def assign_class(output):\n",
        "    return np.argmax(output) + 1\n",
        "\n",
        "# create a confusion matrix\n",
        "\n",
        "\n",
        "# def confusion_matrix():\n",
        "#     return\n",
        "\n",
        "\n",
        "def test_network(is_logistic, weight_hidden, weight_output, data):\n",
        "    # get information from the dataset\n",
        "    num_classes = np.unique(data[:, -1]).size\n",
        "    confusion_matrix = np.zeros((num_classes, num_classes))\n",
        "\n",
        "    num_features = data.shape[1] - 1\n",
        "    sample_size = data.shape[0]\n",
        "    # remove the last column from the inputs list, i.e., remove the class type from inputs\n",
        "    inputs = np.delete(data, len(data[0])-1, 1)\n",
        "\n",
        "    fx, d_fx = choose_curve(is_logistic)\n",
        "    assigned_class = []\n",
        "    true_class = []\n",
        "    count_errors = 0\n",
        "    for i in range(0, sample_size):\n",
        "        # calculate the value for the hidden layer and the output layer\n",
        "        hidden_values = calculate_layer(weight_hidden, fx, inputs[i])\n",
        "        output_values = calculate_layer(weight_output, fx, hidden_values)\n",
        "\n",
        "        # debug output\n",
        "        class_index = assign_class(output_values)\n",
        "        assigned_class.append(class_index)\n",
        "        true_class.append(data[i][-1])\n",
        "        if (true_class[i] != assigned_class[i]):\n",
        "            count_errors += 1\n",
        "        # print(\"Expected: \", true_class[i], \" Attained: \", assigned_class[i])\n",
        "\n",
        "        # debug output\n",
        "        expected_values = calculate_expected_values(\n",
        "            is_logistic, data[i][-1], num_classes)\n",
        "        # print(\"Expected: \")\n",
        "        # print(expected_values)\n",
        "        # print(\"Output: \")\n",
        "      # print(output_values)\n",
        "        confusion_matrix[true_class[i]-1][assigned_class[i]-1] += 1\n",
        "\n",
        "    # print('Matriz de confus√£o')\n",
        "    plt.matshow(confusion_matrix)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "    # debug output\n",
        "    print(\"Erros: \")\n",
        "    print(count_errors)\n",
        "    print(\"Total de amostras: \")\n",
        "    print(sample_size)\n",
        "    # print(\"Peso oculta: \"\n",
        "    # print(weight_hidden)\n",
        "   # print(\"Peso saida: \")    # print(weight_output)\n",
        "    return\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pABtZ55klCFw"
      },
      "source": [
        "Programa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "SS84qE09lBPZ"
      },
      "outputs": [],
      "source": [
        "def backpropagation_algo():\n",
        "    is_logistic = True\n",
        "    # curve = \"logistic\"\n",
        "    data = get_training_data(\"treinamento.csv\")\n",
        "    weight_hidden, weight_output = train_through_data(is_logistic, data)\n",
        "\n",
        "    data = get_training_data(\"teste.csv\")\n",
        "    test_network(is_logistic, weight_hidden, weight_output, data)\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkCmwncLV5hs",
        "outputId": "cfd1edba-b8c1-49d2-8b8d-0e879cde9470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "[-0.34012733 -0.98752709  0.33022976 -0.98285466 -0.99513801]\n",
            "2\n",
            "[-0.40802293 -0.985542    0.2258795  -0.97983381 -0.99408193]\n",
            "2\n",
            "[-0.33957763 -0.98754265  0.33105053 -0.98287766 -0.99514662]\n",
            "2\n",
            "[-0.36131573 -0.98695164  0.29905773 -0.98198281 -0.99483784]\n",
            "2\n",
            "[-0.34598218 -0.98737215  0.32175393 -0.98261999 -0.99505794]\n",
            "2\n",
            "[-0.37923106 -0.98643413  0.27170269 -0.9811965  -0.99456312]\n",
            "2\n",
            "[-0.33992128 -0.98753405  0.33057037 -0.9828644  -0.99514243]\n",
            "2\n",
            "[-0.33961172 -0.9875417   0.33099919 -0.98287626 -0.99514609]\n",
            "2\n",
            "[-0.33959279 -0.98754255  0.33103725 -0.98287735 -0.99514672]\n",
            "2\n",
            "[-0.3398759  -0.98753526  0.33063629 -0.98286622 -0.99514306]\n",
            "2\n",
            "[-0.34124949 -0.98749955  0.32866832 -0.98281194 -0.99512485]\n",
            "2\n",
            "[-0.34059414 -0.98751646  0.32960091 -0.98283777 -0.99513337]\n",
            "2\n",
            "[-0.3406972  -0.9875138   0.32945722 -0.98283366 -0.99513205]\n",
            "2\n",
            "[-0.36991447 -0.98670618  0.28601828 -0.98161057 -0.99470763]\n",
            "2\n",
            "[-0.34148703 -0.98749329  0.32832373 -0.98280249 -0.9951216 ]\n",
            "2\n",
            "[-0.34032203 -0.9875234   0.32998625 -0.98284839 -0.99513683]\n",
            "2\n",
            "[-0.34482137 -0.98740441  0.32347898 -0.98266818 -0.99507535]\n",
            "2\n",
            "[-0.34036509 -0.98752134  0.32990819 -0.98284561 -0.99513538]\n",
            "2\n",
            "[-0.35989391 -0.98699153  0.30119488 -0.98204324 -0.9948589 ]\n",
            "2\n",
            "[-0.35416208 -0.98715027  0.30973427 -0.9822839  -0.99494222]\n",
            "2\n",
            "[-0.36197485 -0.98693267  0.29805757 -0.98195423 -0.99482763]\n",
            "2\n",
            "[-0.33954464 -0.98754377  0.33110492 -0.98287923 -0.99514733]\n",
            "2\n",
            "[-0.38766165 -0.98618049  0.25850716 -0.98081029 -0.99442698]\n",
            "2\n",
            "[-0.34037211 -0.98752165  0.32990484 -0.98284593 -0.99513573]\n",
            "2\n",
            "[-0.34299463 -0.98745159  0.32608856 -0.98274035 -0.99509903]\n",
            "2\n",
            "[-0.35412537 -0.98715088  0.30976808 -0.98228515 -0.99494223]\n",
            "2\n",
            "[-0.34001928 -0.98753069  0.33041148 -0.98285966 -0.99514032]\n",
            "2\n",
            "[-0.33951473 -0.9875453   0.33117258 -0.9828811  -0.99514854]\n",
            "2\n",
            "[-0.33957561 -0.98754265  0.3310539  -0.98287767 -0.99514661]\n",
            "2\n",
            "[-0.34427436 -0.98741845  0.3242614  -0.98268968 -0.99508237]\n",
            "2\n",
            "[-0.34902003 -0.98729157  0.31734157 -0.98249741 -0.9950166 ]\n",
            "2\n",
            "[-0.33934073 -0.98754833  0.33137119 -0.98288659 -0.99514921]\n",
            "2\n",
            "[-0.34140144 -0.98749385  0.32840166 -0.9828042  -0.99512102]\n",
            "2\n",
            "[-0.34857764 -0.98730204  0.31795081 -0.98251401 -0.99502129]\n",
            "2\n",
            "[-0.34098476 -0.98750368  0.32896705 -0.98281971 -0.99512545]\n",
            "2\n",
            "[-0.34180163 -0.98748465  0.32786175 -0.98278956 -0.99511698]\n",
            "2\n",
            "[-0.3394756  -0.9875455   0.33120223 -0.98288188 -0.99514818]\n",
            "2\n",
            "[-0.36464596 -0.98685746  0.29403445 -0.98184002 -0.99478805]\n",
            "2\n",
            "[-0.33967174 -0.98753993  0.33091138 -0.98287364 -0.99514512]\n",
            "2\n",
            "[-0.3407801  -0.98751107  0.32931865 -0.98282986 -0.99513032]\n",
            "2\n",
            "[-0.35493192 -0.98712969  0.30860277 -0.9822525  -0.99493169]\n",
            "2\n",
            "[-0.33943391 -0.98754723  0.33128282 -0.98288414 -0.99514944]\n",
            "2\n",
            "[-0.34961014 -0.98727381  0.31643405 -0.98247133 -0.99500648]\n",
            "2\n",
            "[-0.36771593 -0.98677047  0.28939978 -0.98170762 -0.99474234]\n",
            "2\n",
            "[-0.34189551 -0.98748088  0.32768848 -0.98278454 -0.99511433]\n",
            "2\n",
            "[-0.34018976 -0.98752741  0.3301959  -0.98285413 -0.99513922]\n",
            "2\n",
            "[-0.34063662 -0.98751551  0.32954486 -0.98283623 -0.99513297]\n",
            "2\n",
            "[-0.34111529 -0.98750135  0.32881624 -0.98281554 -0.9951249 ]\n",
            "2\n",
            "[-0.34574581 -0.98737885  0.32211037 -0.98262992 -0.99506164]\n",
            "2\n",
            "[-0.33988811 -0.98753472  0.33061103 -0.98286553 -0.99514265]\n",
            "2\n",
            "[-0.34905268 -0.98728999  0.31727794 -0.98249533 -0.99501545]\n",
            "2\n",
            "[-0.34243565 -0.9874667   0.3269155  -0.98276296 -0.99510711]\n",
            "2\n",
            "[-0.34304492 -0.98745169  0.32605887 -0.98273974 -0.99509987]\n",
            "2\n",
            "[-0.34516938 -0.98739356  0.3229233  -0.98265263 -0.99506883]\n",
            "2\n",
            "[-0.34001697 -0.98753155  0.33043157 -0.98286062 -0.99514113]\n",
            "2\n",
            "[-0.3414068  -0.98749473  0.32842112 -0.98280501 -0.99512199]\n",
            "2\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.3393473  -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143175 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.33934729 -0.98755031  0.33143174 -0.98288836 -0.99515147]\n",
            "2\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.49296201 -0.99092079 -0.17569227 -0.34579223]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.49296201 -0.99092079 -0.17569227 -0.34579223]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.49296201 -0.99092079 -0.17569227 -0.34579224]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569226 -0.34579222]\n",
            "3\n",
            "[-0.9858692  -0.492962   -0.99092079 -0.17569225 -0.34579222]\n",
            "3\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 480x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Erros: \n",
            "175\n",
            "Total de amostras: \n",
            "352\n"
          ]
        }
      ],
      "source": [
        "backpropagation_algo()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "ea9437200182d95efa26cebbb8d9c138f7faf70d27801ebcabc0dc06f6872427"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
