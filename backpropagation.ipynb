{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from numba import njit\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "vl3oTWgKJQwB"
      },
      "outputs": [],
      "source": [
        "# Backpropagation algorithm\n",
        "# default config for the backpropagation algo\n",
        "l_rate = 0.001\n",
        "max_it = 150\n",
        "min_error = 0.1\n",
        "# obs: changing the learning_rate and the initial weight can improve the performance\n",
        "# the current config is the optimal config found for the hyperbolic tangent until this moment\n",
        "\n",
        "# open the csv file and get the data\n",
        "\n",
        "\n",
        "def get_training_data(filename):\n",
        "    with open(filename) as f:\n",
        "        data = pd.read_csv(f)\n",
        "        data = data.values\n",
        "    return data\n",
        "\n",
        "# choose which curve will be used by the neurons of the net\n",
        "\n",
        "# @njit(parallel=True, fastmath=True, cache=True)\n",
        "\n",
        "@njit(cache=True)\n",
        "def fx_tanh(x: np.ndarray) -> np.ndarray:\n",
        "    return np.tanh(x)\n",
        "\n",
        "@njit(cache=True)\n",
        "def d_fx_tanh(x: np.ndarray) -> np.ndarray:\n",
        "    return (1.0/np.cosh(x))**2.0\n",
        "\n",
        "@njit(cache=True)\n",
        "def fx_logistic(x: np.ndarray) -> np.ndarray:\n",
        "    return 1.0/(1+np.exp(-x))\n",
        "\n",
        "@njit(cache=True)\n",
        "def d_fx_logistic(x: np.ndarray) -> np.ndarray:\n",
        "    return np.exp(x)/(1+np.exp(x))**2.0\n",
        "\n",
        "# @njit(cache=True)\n",
        "def choose_curve(is_logistic: bool) -> tuple:\n",
        "    if is_logistic:\n",
        "        return fx_logistic, d_fx_logistic\n",
        "    else:\n",
        "        return fx_tanh, d_fx_tanh\n",
        "\n",
        "# initialize the weights as small random values\n",
        "\n",
        "\n",
        "@njit(cache=True)\n",
        "def initialize_weights(num_classes: int, num_features: int):\n",
        "    # number of inputs (class features)\n",
        "    num_inputs = num_features\n",
        "    # number of output neurons\n",
        "    num_outputs = num_classes\n",
        "    # number of hidden neurons (geometry mean of inputs and outputs)\n",
        "    num_hidden = int(np.sqrt(num_inputs*num_outputs))\n",
        "    # initialize the weights\n",
        "    # add 0.005 in order to prevent 0\n",
        "    weight_hidden = np.random.rand(num_hidden, num_inputs)/100.0 + 0.0005\n",
        "    weight_output = np.random.rand(num_outputs, num_hidden) * 3.0 - 1.5\n",
        "    # initialize the bias, in this case all bias = 0\n",
        "    bias_hidden = np.zeros((num_hidden, num_inputs))\n",
        "    bias_output = np.zeros((num_outputs, num_hidden))\n",
        "    return weight_hidden, weight_output, bias_hidden, bias_output\n",
        "\n",
        "# calculate the output from each neuron of the given layer\n",
        "# each layer is described by set of weights of each neuron\n",
        "\n",
        "\n",
        "def calculate_layer(weights_layer, fx, layer_inputs):\n",
        "    net: np.ndarray = np.dot(layer_inputs, weights_layer.T)\n",
        "    output = fx(net)\n",
        "    return output\n",
        "\n",
        "# calculate the expected output for the class\n",
        "\n",
        "\n",
        "# @njit(cache=True)\n",
        "def calculate_expected_values(is_logistic, class_number, num_classes):\n",
        "    if is_logistic:\n",
        "        expected_values = np.zeros(num_classes)\n",
        "        expected_values[class_number-1] = 1\n",
        "        return expected_values\n",
        "    else:\n",
        "        expected_values = np.full(num_classes, -1)\n",
        "        expected_values[class_number-1] = 1\n",
        "        return expected_values\n",
        "\n",
        "# calculate the error for the output layer\n",
        "\n",
        "@njit(cache=True)\n",
        "def calculate_output_error(is_logistic, weights, expected, attained, inputs, fx, d_fx):\n",
        "    error = (expected - attained)*d_fx(inputs)\n",
        "    return error\n",
        "\n",
        "# calculate the error for the hidden layer\n",
        "# needs revision\n",
        "\n",
        "def calculate_hidden_error(is_logistic, weights_hidden, weights_output, error_output, inputs, fx, d_fx):\n",
        "    error = error_output @ weights_output\n",
        "    hidden = inputs @ weights_hidden.T\n",
        "    return  error*d_fx(hidden)\n",
        "    # return error\n",
        "\n",
        "\n",
        "# adjust the weights of a given layer according to the layer error\n",
        "\n",
        "@njit(cache=True)\n",
        "def adjust_weights(weights, learning_rate, error, layer_input):\n",
        "    new_weights = np.zeros(weights.shape)\n",
        "    for i in range(len(weights)):\n",
        "        new_weights[i] = weights[i] + learning_rate*error[i]*layer_input\n",
        "    return new_weights\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jFC-QSLkbCa0"
      },
      "source": [
        "Treinamento da rede\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "r9ysPZI6bBgt"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#training with an unbalanced dataset\n",
        "#train a neuron net with a specificied curve and data\n",
        "def train_through_data(is_logistic, data):\n",
        "  #get information from the dataset\n",
        "  num_classes = np.unique(data[:, -1]).size\n",
        "  num_features = data.shape[1] - 1\n",
        "  sample_size = data.shape[0]\n",
        "\n",
        "  # remove the last column from the inputs list, i.e., remove the class type from inputs\n",
        "  inputs = np.delete(data, len(data[0])-1, 1)\n",
        "  \n",
        "  #initialize the initial weights\n",
        "  weight_hidden, weight_output, bias_hidden, bias_output = initialize_weights(num_classes, num_features)\n",
        "  #get the function for the choosen curve\n",
        "  fx, d_fx = choose_curve(is_logistic)\n",
        "  \n",
        "  \n",
        "  #train until max_it\n",
        "  for j in range(0, max_it):\n",
        "    #train the net for sample in dataset\n",
        "    for i in range(0, sample_size):\n",
        "      #choose a random sample in order to prevent overfitting\n",
        "      new_i = random.randint(0, sample_size-1)\n",
        "      \n",
        "      #calculate the expected value for this set of features\n",
        "      expected_values = calculate_expected_values(is_logistic, data[new_i][-1], num_classes)\n",
        "      \n",
        "      #calculate the value for the hidden layer and the output layer\n",
        "      hidden_values = calculate_layer(weight_hidden, fx, inputs[new_i])\n",
        "      output_values = calculate_layer(weight_output, fx, hidden_values)\n",
        "      \n",
        "      #calculate the error for each layer\n",
        "      error_output_layer = calculate_output_error(is_logistic, weight_output, expected_values, output_values, hidden_values, fx, d_fx)\n",
        "      error_hidden_layer = calculate_hidden_error(is_logistic, weight_hidden, weight_output, error_output_layer, inputs[new_i], fx, d_fx)\n",
        "      \n",
        "      #adjust weights for each layer\n",
        "      weight_output = adjust_weights(weight_output, l_rate, error_output_layer, hidden_values)\n",
        "      weight_hidden = adjust_weights(weight_hidden, l_rate, error_hidden_layer, inputs[new_i])\n",
        "    if(j % 100 == 0):\n",
        "      print(j)\n",
        "  #return the trained values for each layer\n",
        "  return weight_hidden, weight_output\n",
        "\n",
        "\n",
        "\n",
        "# #experimental training with a balanced dataset\n",
        "# def train_through_data(is_logistic, data):\n",
        "#   #get information from the dataset\n",
        "#   num_classes = np.unique(data[:, -1]).size\n",
        "#   num_features = data.shape[1] - 1\n",
        "#   sample_size = len(data)\n",
        "\n",
        "#   #initialize the initial weights\n",
        "#   weight_hidden, weight_output, bias_hidden, bias_output = initialize_weights(num_classes, num_features)\n",
        "#   #get the function for the choosen curve\n",
        "#   fx, d_fx = choose_curve(is_logistic)\n",
        "  \n",
        "#   current_class = 1\n",
        "\n",
        "#   #train until max_it\n",
        "#   for j in range(0, max_it):\n",
        "#     #train the net for sample in dataset\n",
        "#     for i in range(0, sample_size):\n",
        "#       #choose a random sample in order to prevent overfitting\n",
        "#       sample = choose_sample(current_class, data)\n",
        "      \n",
        "#       #separate the class from the inputs list, i.e., remove the class type from inputs\n",
        "#       sample_class = sample[-1]\n",
        "#       inputs = np.delete(sample, len(sample)-1, 0)\n",
        "\n",
        "#       #calculate the expected value for this set of features\n",
        "#       expected_values = calculate_expected_values(is_logistic, sample_class, num_classes)\n",
        "      \n",
        "#       #calculate the value for the hidden layer and the output layer\n",
        "#       hidden_values = calculate_layer(weight_hidden, fx, inputs)\n",
        "#       output_values = calculate_layer(weight_output, fx, hidden_values)\n",
        "      \n",
        "#       #calculate the error for each layer\n",
        "#       error_output_layer = calculate_output_error(is_logistic, weight_output, expected_values, output_values, hidden_values)\n",
        "#       error_hidden_layer = calculate_hidden_error(is_logistic, weight_hidden, weight_output, error_output_layer, inputs)\n",
        "#       #print(\"Expected: \")\n",
        "#       #print(expected_values)\n",
        "#       #print(\"Output: \")\n",
        "#       #print(output_values)\n",
        "      \n",
        "#       #adjust weights for each layer\n",
        "#       weight_output = adjust_weights(weight_output, l_rate, error_output_layer, hidden_values)\n",
        "#       weight_hidden = adjust_weights(weight_hidden, l_rate, error_hidden_layer, inputs)\n",
        "\n",
        "#       current_class %= num_classes\n",
        "#       current_class += 1\n",
        "#     if(j % 100 == 0):\n",
        "#       print(j)\n",
        "#   #return the trained values for each layer\n",
        "#   return weight_hidden, weight_output\n",
        "\n",
        "\"\"\"\"\"\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XE2s_3ZWho05"
      },
      "source": [
        "Testagem da rede\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "K6B6S_yvhoTR"
      },
      "outputs": [],
      "source": [
        "# the assigned class will be the index with the higher value\n",
        "#@njit(cache=True)\n",
        "def assign_class(output):\n",
        "    return np.argmax(output) + 1\n",
        "\n",
        "# create a confusion matrix\n",
        "\n",
        "\n",
        "# def confusion_matrix():\n",
        "#     return\n",
        "\n",
        "\n",
        "def test_network(is_logistic, weight_hidden, weight_output, data):\n",
        "    # get information from the dataset\n",
        "    num_classes = np.unique(data[:, -1]).size\n",
        "    confusion_matrix = np.zeros((num_classes, num_classes))\n",
        "\n",
        "    num_features = data.shape[1] - 1\n",
        "    sample_size = data.shape[0]\n",
        "    # remove the last column from the inputs list, i.e., remove the class type from inputs\n",
        "    inputs = np.delete(data, len(data[0])-1, 1)\n",
        "\n",
        "    fx, d_fx = choose_curve(is_logistic)\n",
        "    assigned_class = []\n",
        "    true_class = []\n",
        "    count_errors = 0\n",
        "    for i in range(0, sample_size):\n",
        "        # calculate the value for the hidden layer and the output layer\n",
        "        hidden_values = calculate_layer(weight_hidden, fx, inputs[i])\n",
        "        output_values = calculate_layer(weight_output, fx, hidden_values)\n",
        "\n",
        "        # debug output\n",
        "        class_index = assign_class(output_values)\n",
        "        assigned_class.append(class_index)\n",
        "        true_class.append(data[i][-1])\n",
        "        if (true_class[i] != assigned_class[i]):\n",
        "            count_errors += 1\n",
        "        # print(\"Expected: \", true_class[i], \" Attained: \", assigned_class[i])\n",
        "\n",
        "        # debug output\n",
        "        expected_values = calculate_expected_values(\n",
        "            is_logistic, data[i][-1], num_classes)\n",
        "        # print(\"Expected: \")\n",
        "        # print(expected_values)\n",
        "        # print(\"Output: \")\n",
        "      # print(output_values)\n",
        "        confusion_matrix[true_class[i]-1][assigned_class[i]-1] += 1\n",
        "\n",
        "    # print('Matriz de confusão')\n",
        "    plt.matshow(confusion_matrix)\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "    # debug output\n",
        "    print(\"Erros: \")\n",
        "    print(count_errors)\n",
        "    print(\"Total de amostras: \")\n",
        "    print(sample_size)\n",
        "    # print(\"Peso oculta: \"\n",
        "    # print(weight_hidden)\n",
        "   # print(\"Peso saida: \")    # print(weight_output)\n",
        "    return\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pABtZ55klCFw"
      },
      "source": [
        "Programa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "SS84qE09lBPZ"
      },
      "outputs": [],
      "source": [
        "def backpropagation_algo():\n",
        "    is_logistic = True\n",
        "    # curve = \"logistic\"\n",
        "    data = get_training_data(\"treinamento.csv\")\n",
        "    weight_hidden, weight_output = train_through_data(is_logistic, data)\n",
        "\n",
        "    data = get_training_data(\"teste.csv\")\n",
        "    test_network(is_logistic, weight_hidden, weight_output, data)\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkCmwncLV5hs",
        "outputId": "cfd1edba-b8c1-49d2-8b8d-0e879cde9470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 480x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Erros: \n",
            "0\n",
            "Total de amostras: \n",
            "352\n"
          ]
        }
      ],
      "source": [
        "backpropagation_algo()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "ea9437200182d95efa26cebbb8d9c138f7faf70d27801ebcabc0dc06f6872427"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
